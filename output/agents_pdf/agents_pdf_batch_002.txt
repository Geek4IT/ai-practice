--- 第 6 页 ---
Voting: Running the same task multiple times to get diverse
outputs.
The parallelization worklow
When to use this workflow: Parallelization is effective when the
divided subtasks can be parallelized for speed, or when multiple
perspectives or attempts are needed for higher confidence results. For
complex tasks with multiple considerations, LLMs generally perform
better when each consideration is handled by a separate LLM call,
allowing focused attention on each specific aspect.
Examples where parallelization is useful:
Sectioning:
Implementing guardrails where one model instance processes
user queries while another screens them for inappropriate
content or requests. This tends to perform better than having
the same LLM call handle both guardrails and the core
response.
Automating evals for evaluating LLM performance, where each
LLM call evaluates a different aspect of the model’s
performance on a given prompt.
Voting:
Reviewing a piece of code for vulnerabilities, where several
different prompts review and flag the code if they find a
problem.2024/12/22 16:07 Building effective agents \ Anthropic
https://www.anthropic.com/research/building-effective-agents 6/15

--- 第 7 页 ---
Evaluating whether a given piece of content is inappropriate,
with multiple prompts evaluating different aspects or
requiring different vote thresholds to balance false positives
and negatives.
Worklow: Orchestrator-workers
In the orchestratorworkers workflow, a central LLM dynamically
breaks down tasks, delegates them to worker LLMs, and synthesizes
their results.
The orchestrator-workers worklow
When to use this workflow: This workflow is wellsuited for complex
tasks where you can’t predict the subtasks needed in coding, for
example, the number of files that need to be changed and the nature of
the change in each file likely depend on the task. Whereas it’s
topographically similar, the key difference from parallelization is its
flexibilitysubtasks aren't predefined, but determined by the
orchestrator based on the specific input.
Example where orchestratorworkers is useful:
Coding products that make complex changes to multiple files each
time.
Search tasks that involve gathering and analyzing information
from multiple sources for possible relevant information.
Worklow: Evaluator-optimizer2024/12/22 16:07 Building effective agents \ Anthropic
https://www.anthropic.com/research/building-effective-agents 7/15

--- 第 8 页 ---
In the evaluatoroptimizer workflow, one LLM call generates a
response while another provides evaluation and feedback in a loop.
The evaluator-optimizer worklow
When to use this workflow: This workflow is particularly effective
when we have clear evaluation criteria, and when iterative refinement
provides measurable value. The two signs of good fit are, first, that
LLM responses can be demonstrably improved when a human
articulates their feedback; and second, that the LLM can provide such
feedback. This is analogous to the iterative writing process a human
writer might go through when producing a polished document.
Examples where evaluatoroptimizer is useful:
Literary translation where there are nuances that the translator
LLM might not capture initially, but where an evaluator LLM can
provide useful critiques.
Complex search tasks that require multiple rounds of searching
and analysis to gather comprehensive information, where the
evaluator decides whether further searches are warranted.
Agents
Agents are emerging in production as LLMs mature in key capabilities
understanding complex inputs, engaging in reasoning and planning,
using tools reliably, and recovering from errors. Agents begin their
work with either a command from, or interactive discussion with, the
human user. Once the task is clear, agents plan and operate2024/12/22 16:07 Building effective agents \ Anthropic
https://www.anthropic.com/research/building-effective-agents 8/15

--- 第 9 页 ---
independently, potentially returning to the human for further
information or judgement. During execution, it's crucial for the agents
to gain “ground truth” from the environment at each step such as tool
call results or code execution to assess its progress. Agents can then
pause for human feedback at checkpoints or when encountering
blockers. The task often terminates upon completion, but it’s also
common to include stopping conditions such as a maximum number
of iterations to maintain control.
Agents can handle sophisticated tasks, but their implementation is
often straightforward. They are typically just LLMs using tools based
on environmental feedback in a loop. It is therefore crucial to design
toolsets and their documentation clearly and thoughtfully. We expand
on best practices for tool development in Appendix 2 "Prompt
Engineering your Tools".
Autonomous agent
When to use agents: Agents can be used for openended problems
where it’s difficult or impossible to predict the required number of
steps, and where you can’t hardcode a fixed path. The LLM will
potentially operate for many turns, and you must have some level of
trust in its decisionmaking. Agents' autonomy makes them ideal for
scaling tasks in trusted environments.
The autonomous nature of agents means higher costs, and the
potential for compounding errors. We recommend extensive testing in
sandboxed environments, along with the appropriate guardrails.2024/12/22 16:07 Building effective agents \ Anthropic
https://www.anthropic.com/research/building-effective-agents 9/15

--- 第 10 页 ---
Examples where agents are useful:
The following examples are from our own implementations:
A coding Agent to resolve SWEbench tasks, which involve edits to
many files based on a task description;
Our “computer use” reference implementation, where Claude uses
a computer to accomplish tasks.
High-level low of a coding agent
Combining and customizing
these patterns
These building blocks aren't prescriptive. They're common patterns
that developers can shape and combine to fit different use cases. The
key to success, as with any LLM features, is measuring performance
and iterating on implementations. To repeat: you should consider
adding complexity only when it demonstrably improves outcomes.2024/12/22 16:07 Building effective agents \ Anthropic
https://www.anthropic.com/research/building-effective-agents 10/15

