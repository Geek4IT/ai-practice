--- 第 1 页 ---
Product
Building efective agents
2024年 12 ⽉ 20 ⽇
Over the past year, we've worked with dozens of teams building large
language model LLM agents across industries. Consistently, the most
successful implementations weren't using complex frameworks or
specialized libraries. Instead, they were building with simple,
composable patterns.
In this post, we share what we’ve learned from working with our
customers and building agents ourselves, and give practical advice for
developers on building effective agents.
What are agents?
"Agent" can be defined in several ways. Some customers define agents
as fully autonomous systems that operate independently over
extended periods, using various tools to accomplish complex tasks.
Others use the term to describe more prescriptive implementations
that follow predefined workflows. At Anthropic, we categorize all these
variations as agentic systems, but draw an important architectural
distinction between workflows and agents:
Workflows are systems where LLMs and tools are orchestrated
through predefined code paths.
Agents, on the other hand, are systems where LLMs dynamically
direct their own processes and tool usage, maintaining control
over how they accomplish tasks.
Below, we will explore both types of agentic systems in detail. In
Appendix 1 “Agents in Practice”, we describe two domains where
customers have found particular value in using these kinds of systems.2024/12/22 16:07 Building effective agents \ Anthropic
https://www.anthropic.com/research/building-effective-agents 1/15

--- 第 2 页 ---
When (and when not) to use agents
When building applications with LLMs, we recommend finding the
simplest solution possible, and only increasing complexity when
needed. This might mean not building agentic systems at all. Agentic
systems often trade latency and cost for better task performance, and
you should consider when this tradeoff makes sense.
When more complexity is warranted, workflows offer predictability
and consistency for welldefined tasks, whereas agents are the better
option when flexibility and modeldriven decisionmaking are needed
at scale. For many applications, however, optimizing single LLM calls
with retrieval and incontext examples is usually enough.
When and how to use frameworks
There are many frameworks that make agentic systems easier to
implement, including:
LangGraph from LangChain;
Amazon Bedrock's AI Agent framework;
Rivet, a drag and drop GUI LLM workflow builder; and
Vellum, another GUI tool for building and testing complex
workflows.
These frameworks make it easy to get started by simplifying standard
lowlevel tasks like calling LLMs, defining and parsing tools, and
chaining calls together. However, they often create extra layers of
abstraction that can obscure the underlying prompts   and responses,
making them harder to debug. They can also make it tempting to add
complexity when a simpler setup would suffice.
We suggest that developers start by using LLM APIs directly: many
patterns can be implemented in a few lines of code. If you do use a
framework, ensure you understand the underlying code. Incorrect
assumptions about what's under the hood are a common source of
customer error.2024/12/22 16:07 Building effective agents \ Anthropic
https://www.anthropic.com/research/building-effective-agents 2/15

--- 第 3 页 ---
See our cookbook for some sample implementations.
Building blocks, worklows,
and agents
In this section, we’ll explore the common patterns for agentic systems
we’ve seen in production. We'll start with our foundational building
blockthe augmented LLMand progressively increase complexity,
from simple compositional workflows to autonomous agents.
Building block: The augmented LLM
The basic building block of agentic systems is an LLM enhanced with
augmentations such as retrieval, tools, and memory. Our current
models can actively use these capabilitiesgenerating their own
search queries, selecting appropriate tools, and determining what
information to retain.
The augmented LLM
We recommend focusing on two key aspects of the implementation:
tailoring these capabilities to your specific use case and ensuring they
provide an easy, welldocumented interface for your LLM. While there
are many ways to implement these augmentations, one approach is
through our recently released Model Context Protocol, which allows2024/12/22 16:07 Building effective agents \ Anthropic
https://www.anthropic.com/research/building-effective-agents 3/15

--- 第 4 页 ---
developers to integrate with a growing ecosystem of thirdparty tools
with a simple client implementation.
For the remainder of this post, we'll assume each LLM call has access
to these augmented capabilities.
Worklow: Prompt chaining
Prompt chaining decomposes a task into a sequence of steps, where
each LLM call processes the output of the previous one. You can add
programmatic checks see "gate” in the diagram below on any
intermediate steps to ensure that the process is still on track.
The prompt chaining worklow
When to use this workflow: This workflow is ideal for situations where
the task can be easily and cleanly decomposed into fixed subtasks. The
main goal is to trade off latency for higher accuracy, by making each
LLM call an easier task.
Examples where prompt chaining is useful:
Generating Marketing copy, then translating it into a different
language.
Writing an outline of a document, checking that the outline meets
certain criteria, then writing the document based on the outline.
Worklow: Routing2024/12/22 16:07 Building effective agents \ Anthropic
https://www.anthropic.com/research/building-effective-agents 4/15

--- 第 5 页 ---
Routing classifies an input and directs it to a specialized followup task.
This workflow allows for separation of concerns, and building more
specialized prompts. Without this workflow, optimizing for one kind of
input can hurt performance on other inputs.
The routing worklow
When to use this workflow: Routing works well for complex tasks
where there are distinct categories that are better handled separately,
and where classification can be handled accurately, either by an LLM
or a more traditional classification modelalgorithm.
Examples where routing is useful:
Directing different types of customer service queries general
questions, refund requests, technical support into different
downstream processes, prompts, and tools.
Routing easycommon questions to smaller models like Claude 3.5
Haiku and hardunusual questions to more capable models like
Claude 3.5 Sonnet to optimize cost and speed.
Worklow: Parallelization
LLMs can sometimes work simultaneously on a task and have their
outputs aggregated programmatically. This workflow, parallelization,
manifests in two key variations:
Sectioning: Breaking a task into independent subtasks run in
parallel.2024/12/22 16:07 Building effective agents \ Anthropic
https://www.anthropic.com/research/building-effective-agents 5/15

